
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> #######################################
> # three ways to estimate the baseline #
> #######################################
> 
> # generate example data set
> source("survival_functions.R")
Loading required package: Matrix
Loading required package: foreach
Loaded glmnet 2.0-16


Attaching package: ‘ncvreg’

The following object is masked from ‘package:survival’:

    heart

> n <- 150
> p <- 1000
> c <- 4:9/10
> rep <- 200
> 
> result_lambda <- array(NA,dim = c(5,length(c),rep),dimnames = list(c("NA","Full","CV","LP","Oracle"),
+                                                                      as.character(c),
+                                                                      NULL))
> result_MSER <- array(NA,dim = c(5,length(c),rep),dimnames = list(c("NA","Full","CV","LP","Oracle"),
+                                                                  as.character(c),
+                                                                  NULL))
> 
> for(R in 1:rep){
+   for(j in 1:length(c)){
+     beta <- generatebeta(p,nbeta = 10 ,c = c[j])
+     data <- genSurvData(n=n , beta = beta, cpct = 0.1, sd = 1)
+ 
+     #initial fit
+     fit <- ncvsurv(X = data$x, y = data$y, penalty = "lasso")
+     lambda <- fit$lambda
+     l <- length(lambda)
+     
+     # oracle fit
+     fit_oracle <- numeric(p)
+     fit_oracle[1:10] <- coxph(data$y ~ data$x[,1:10])$coef
+     
+     MSE_oracle <- mean((fit_oracle - beta)^2)
+     MSE_all <- apply(fit$beta,2,function(x){mean((x - beta)^2)})
+     log_MSE_ratio <- log(MSE_all/MSE_oracle)
+     
+     # allocation for cross validation
+     foldid <- numeric(n)
+     eta.cv <- matrix(nrow = n, ncol = l)
+     colnames(eta.cv) <- lambda
+     foldid[data$y[,2] == 1] <- sample(1:10, sum(data$y[,2]), replace = TRUE)
+     foldid[data$y[,2] == 0] <- sample(1:10, sum(1 - data$y[,2]), replace = TRUE)
+     ind <- order(data$y[,1])
+     d <- as.numeric(data$y[ind, 2])
+     
+     # get cross-validated linear predictors
+     for(i in 1:10){
+       ifold <- foldid == i
+       cvfit <- ncvsurv(X = data$x[!ifold,], y = data$y[!ifold,], lambda = lambda, penalty = "lasso")
+       cvlambda <- cvfit$lambda
+       eta.cv[ifold,lambda%in%cvlambda] <- predict(cvfit,X = data$x[ifold,], type = "link")
+     }
+     
+     eta.cv <- eta.cv[,apply(eta.cv,2,function(x){sum(is.na(x)) == 0})]
+     ncol(eta.cv)
+     w.cv <- exp(eta.cv[ind, , drop = FALSE])
+     
+     #-------------------------------------------------------
+     # completely non-parametric (-log of KM estimator)
+     # KM <- survfit(data$y~1)
+     # BH_KM <- -log(KM$surv)
+     # 
+     # val_KM <- apply(w.cv, 2, function(x){ 
+     #   M <- d - BH_KM*x
+     #   dev <- sign(M) * sqrt(-2 * (M + ifelse(d == 0, 0, d * 
+     #                                            log(d - M))))
+     #   sum(dev^2)})
+     
+     #-------------------------------------------------------
+     # completely non-parametric (nelson aalen estimator)
+     KM <- survfit(data$y~1)
+     BH_NA <- cumsum(KM$n.event/KM$n.risk)
+     
+     val_NA <- apply(w.cv, 2, function(x){ 
+       M <- d - BH_NA*x
+       dev <- sign(M) * sqrt(-2 * (M + ifelse(d == 0, 0, d * 
+                                                log(d - M))))
+       sum(dev^2)})
+     
+     #-------------------------------------------------------
+     # with eta from full fit
+     ind <- order(data$y[,1])
+     d <- as.numeric(data$y[ind, 2])  
+     Eta <- predict(fit,data$x,type = "link")
+     w <- exp(Eta[ind, , drop = FALSE])
+     BH_full <- apply(w, 2, function(x){ 
+       r <- rev(cumsum(rev(x)))
+       a <- ifelse(d, (1 - x/r)^(1/x), 1)
+       cumsum(1-a)
+       }
+     )
+     BH_full <- BH_full[,1:ncol(w.cv)]
+     
+     val_full <- apply(w.cv*BH_full, 2, function(x){ 
+       M <- d - x
+       dev <- sign(M) * sqrt(-2 * (M + ifelse(d == 0, 0, d * 
+                                                log(d - M))))
+       sum(dev^2)})
+     
+     
+     #-------------------------------------------------------
+     # with cross-validated eta
+     
+     val_cv <- apply(w.cv, 2, function(x){ 
+       r <- rev(cumsum(rev(x)))
+       a <- ifelse(d, (1 - x/r)^(1/x), 1)
+       BH0 <- cumsum(1-a)
+       M <- d - BH0*x
+       dev <- sign(M) * sqrt(-2 * (M + ifelse(d == 0, 0, d * 
+                                                log(d - M))))
+       #dev <- (- M - ifelse(d == 0, 0, d * log(d - M)))
+       sum(dev^2)})
+     
+     #-------------------------------------------------------
+     # partial likelihood built from linear predictors
+     eta.cv.ordered <- eta.cv[ind,,drop = FALSE]
+     r <- apply(eta.cv.ordered, 2, function(x) rev(cumsum(rev(exp(x)))))
+     pl <- -2 * (crossprod(d, eta.cv.ordered) - crossprod(d, log(r)))
+     colnames(pl) <- colnames(eta.cv)
+ 
+ #-------------------------------------------------------
+ # extract results
+   id <- c(which.min(val_NA), which.min(val_full), which.min(val_cv), which.min(pl),
+           which.min(log_MSE_ratio))
+   result_lambda[,j,R] <- lambda[id]
+     
+   result_MSER[,j,R] <- log_MSE_ratio[id]
+     
+   }
+ }
There were 50 or more warnings (use warnings() to see the first 50)
> 
> apply(result_lambda,c(1,2),mean)
             0.4        0.5        0.6        0.7        0.8        0.9
NA     0.1531156 0.13459523 0.12513231 0.12173531 0.12128493 0.12103524
Full   0.2533626 0.22752627 0.20838327 0.17671556 0.15884763 0.14135836
CV     0.1833635 0.15757305 0.14193479 0.13208719 0.12561229 0.11999692
LP     0.1441179 0.12138551 0.10780278 0.09812569 0.09140490 0.08490347
Oracle 0.1059156 0.08691681 0.07606031 0.06653992 0.05921878 0.05338516
> apply(result_MSER,c(1,2),mean)
            0.4      0.5      0.6      0.7      0.8      0.9
NA     2.403790 2.510747 2.828852 3.008378 3.172258 3.346309
Full   2.707480 2.939678 3.259189 3.359558 3.422824 3.493431
CV     2.522769 2.654207 2.950467 3.097088 3.207967 3.328127
LP     2.368405 2.408889 2.659506 2.717266 2.776081 2.826433
Oracle 2.225339 2.219431 2.422909 2.397275 2.366963 2.334661
> 
> save(result_lambda,result_MSER,file = "baseline.RData")
> 
> proc.time()
    user   system  elapsed 
4876.553    0.983 4879.962 
